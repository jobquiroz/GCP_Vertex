{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05i - Vertex AI > Training > Hyperparameter Tuning Jobs - With Custom Container\n",
    "\n",
    "### 05 Series Overview\n",
    "Where a model gets trained is where it consumes computing resources.  With Vertex AI, you have choices for configuring the computing resources available at training.  This notebook is an example of an execution environment.  When it was set up there were choices for machine type and accelerators (GPUs).  \n",
    "\n",
    "In the `05` notebook, the model training happened directly in the notebook.  The models were then imported to Vertex AI and deployed to an endpoint for online predictions. \n",
    "\n",
    "In this `05a-05i` series of demonstrations, the same model is trained using managed computing resources in Vertex AI as custom training jobs.  These jobs will be demonstrated as:\n",
    "\n",
    "-  Custom Job from a python script (`05a`), python source distribution (`05b`), and custom container (`05c`)\n",
    "-  Training Pipeline that trains and saves models from a python script (`05d`), python source distribution (`05e`), and custom container (`05f`)\n",
    "-  Hyperparameter Tuning Jobs from a python script (`05g`), python source distribution (`05h`), and custom container (`05i`)\n",
    "\n",
    "### This Notebook (`05i`): An extension of `05c` with Hyperparmeter Tuning - And Tensorboard HParams  \n",
    "This notebook trains the same Tensorflow Keras model from `05` by first modifying and saving the training code as a Python module on a custom container (same as `05c`).  While this example fits nicely in a single script, larger examples will benefit from the flexibility offered by source distributions or module storage and this notebook gives an example of making the shift. \n",
    "\n",
    "The training code is stored directly on the custom container as part of the Docker build process.  This build process uses a pre-built container as the base image and adds both packages and the training code as a Python module.  This container is specified in the setup of a custom training job and also assigned compute resources for executing the training in a managed service.  This is done with the [Vertex AI Python SDK](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#) using the class [`aiplatform.CustomJob()`](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.CustomJob).\n",
    "\n",
    "The Custom Job is then used as the input for a Vertex AI > Training > Hyperparameter Tuning Job.  This runs and manages the tuning loops for the number of trials in each loop, collects the metric(s) and manages the parameters with the selected search algorithm for parameter modification.  This is done with the [Vertex AI Python SDK](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#) using the class [`aiplatform.HyperparameterTuningJob()`](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.HyperparameterTuningJob).\n",
    "\n",
    "The training can be reviewed with Vertex AI's managed Tensorboard under Experiments > Experiments, or by clicking on the `05i...` job under Training > Hyperparameter Tuning Jobs and then clicking the 'Open Tensorboard' link.  **Click on the HParams tab in Tensorboard to review the hyperparameters and metrics.**\n",
    "\n",
    "<img src=\"architectures/overview/Training.png\">\n",
    "\n",
    "### Prerequisites:\n",
    "-  01 - BigQuery - Table Data Source\n",
    "-  Understanding:\n",
    "    -  05 - Vertex AI > Notebooks - Models Built in Notebooks with Tensorflow\n",
    "        -  Contains a more granular review of the Tensorflow model training\n",
    "\n",
    "### Overview:\n",
    "- Setup Environment\n",
    "- Setup Vertex AI > Experiments for Tensorboard\n",
    "- Training\n",
    "    - Assemble a Python file/script for training\n",
    "    - Create a Custom Container containing the Python Script\n",
    "    - Store the Custom Container in Artifact Registry\n",
    "    - Setup the Vertex AI > Training > Custom Job\n",
    "    - Setup the Vertex AI > Training > Hyperparameter Tuning Job\n",
    "    - Run the Vertex AI > Training > Hyperparameter Tuning Job\n",
    "    - Review the metrics across Hyperparamter Tuning Jobs and pick the best model\n",
    "- Serving\n",
    "    - Upload the chosen model to Vertex AI > Models\n",
    "    - Create an Endpoint with Vertex AI > Endpoints\n",
    "    - Deploy the Model to the Endpoint\n",
    "- Prediction\n",
    "    - Prepare a record for prediction\n",
    "    - Get Predictions with Python Client\n",
    "    - Get Predictions with REST\n",
    "    - Get Prediction with gcloud CLI\n",
    "\n",
    "### Resources:\n",
    "- [Vertex AI Custom Container For Training](https://cloud.google.com/vertex-ai/docs/training/containers-overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Vertex AI - Conceptual Flow\n",
    "\n",
    "<img src=\"architectures/slides/05i_arch.png\">\n",
    "\n",
    "---\n",
    "## Vertex AI - Workflow\n",
    "\n",
    "<img src=\"architectures/slides/05i_console.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "PROJECT_ID='ma-mx-presales-lab'\n",
    "DATANAME = 'fraud'\n",
    "NOTEBOOK = '05i'\n",
    "\n",
    "# Resources\n",
    "BASE_IMAGE = 'gcr.io/deeplearning-platform-release/tf-cpu.2-3'\n",
    "DEPLOY_IMAGE ='us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-7:latest'\n",
    "TRAIN_COMPUTE = 'n1-standard-4'\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id' # add more variables to the string with space delimiters\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "bigquery = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET = \"vertex-ai-mlops-bucket\"\n",
    "URI = f\"gs://{BUCKET}/{DATANAME}/models/{NOTEBOOK}\"\n",
    "DIR = f\"temp/{NOTEBOOK}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'825075454589-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Give service account roles/storage.objectAdmin permissions\n",
    "# Console > IMA > Select Account <projectnumber>-compute@developer.gserviceaccount.com > edit - give role\n",
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Get Vertex AI Experiments Tensorboard Instance Name\n",
    "[Vertex AI Experiments](https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview) has managed [Tensorboard](https://www.tensorflow.org/tensorboard) instances that you can track Tensorboard Experiments (a training run or hyperparameter tuning sweep).  \n",
    "\n",
    "The training job will show up as an experiment for the Tensorboard instance and have the same name as the training job ID.\n",
    "\n",
    "This code checks to see if a Tensorboard Instance has been created in the project, retrieves it if so, creates it otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tb = aiplatform.Tensorboard.list(filter=f'display_name={DATANAME}')\n",
    "# if tb:\n",
    "#     tb = tb[0]\n",
    "# else:\n",
    "#     tb = aiplatform.Tensorboard.create(display_name = DATANAME, labels = {'notebook':f'{DATANAME}'})\n",
    "\n",
    "#tb.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble Python File for Training\n",
    "\n",
    "Create the main python trainer file as `/train.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {DIR}/source/trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temp/05i/source/trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DIR}/source/trainer/train.py\n",
    "\n",
    "# package import\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from google.cloud import bigquery\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import hypertune\n",
    "\n",
    "# import argument to local variables\n",
    "parser = argparse.ArgumentParser()\n",
    "# the passed param, dest: a name for the param, default: if absent fetch this param from the OS, type: type to convert to, help: description of argument\n",
    "parser.add_argument('--epochs', dest = 'epochs', default = 10, type = int, help = 'Number of Epochs')\n",
    "parser.add_argument('--batch_size', dest = 'batch_size', default = 32, type = int, help = 'Batch Size')\n",
    "parser.add_argument('--var_target', dest = 'var_target', type=str)\n",
    "parser.add_argument('--var_omit', dest = 'var_omit', type=str, nargs='*')\n",
    "parser.add_argument('--project_id', dest = 'project_id', type=str)\n",
    "parser.add_argument('--dataname', dest = 'dataname', type=str)\n",
    "parser.add_argument('--region', dest = 'region', type=str)\n",
    "parser.add_argument('--notebook', dest = 'notebook', type=str)\n",
    "# hyperparameters\n",
    "parser.add_argument('--lr',dest='learning_rate', required=True, type=float, help='Learning Rate')\n",
    "parser.add_argument('--m',dest='momentum', required=True, type=float, help='Momentum')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# setup tensorboard hparams\n",
    "#    \"lr\": aiplatform.hyperparameter_tuning.DoubleParameterSpec(min=0.001, max=0.1, scale=\"log\"),\n",
    "#    \"m\": aiplatform.hyperparameter_tuning.DoubleParameterSpec(min=1e-7, max=0.9, scale=\"linear\")\n",
    "HP_LEARNING_RATE = hp.HParam('learning_rate',hp.RealInterval(0.0, 1.0))\n",
    "HP_MOMENTUM = hp.HParam('momentum', hp.RealInterval(0.0,1.0))\n",
    "hparams = {\n",
    "    HP_LEARNING_RATE: args.learning_rate,\n",
    "    HP_MOMENTUM: args.momentum\n",
    "}\n",
    "\n",
    "# built in parameters for data source:\n",
    "PROJECT_ID = args.project_id\n",
    "DATANAME = args.dataname\n",
    "REGION = args.region\n",
    "NOTEBOOK = args.notebook\n",
    "\n",
    "# clients\n",
    "bigquery = bigquery.Client(project = PROJECT_ID)\n",
    "\n",
    "# get schema from bigquery source\n",
    "query = f\"SELECT * FROM {DATANAME}.INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{DATANAME}_prepped'\"\n",
    "schema = bigquery.query(query).to_dataframe()\n",
    "\n",
    "# get number of classes from bigquery source\n",
    "nclasses = bigquery.query(query = f'SELECT DISTINCT {args.var_target} FROM {DATANAME}.{DATANAME}_prepped WHERE {args.var_target} is not null').to_dataframe()\n",
    "nclasses = nclasses.shape[0]\n",
    "\n",
    "# Make a list of columns to omit\n",
    "OMIT = args.var_omit + ['splits']\n",
    "\n",
    "# use schema to prepare a list of columns to read from BigQuery\n",
    "selected_fields = schema[~schema.column_name.isin(OMIT)].column_name.tolist()\n",
    "\n",
    "# all the columns in this data source are either float64 or int64\n",
    "output_types = [dtypes.float64 if x=='FLOAT64' else dtypes.int64 for x in schema[~schema.column_name.isin(OMIT)].data_type.tolist()]\n",
    "\n",
    "# remap input data to Tensorflow inputs of features and target\n",
    "def transTable(row_dict):\n",
    "    target=row_dict.pop(args.var_target)\n",
    "    target = tf.one_hot(tf.cast(target,tf.int64), nclasses)\n",
    "    target = tf.cast(target, tf.float32)\n",
    "    return(row_dict, target)\n",
    "\n",
    "# function to setup a bigquery reader with Tensorflow I/O\n",
    "def bq_reader(split):\n",
    "    reader = BigQueryClient()\n",
    "\n",
    "    training = reader.read_session(\n",
    "        parent = f\"projects/{PROJECT_ID}\",\n",
    "        project_id = PROJECT_ID,\n",
    "        table_id = f\"{DATANAME}_prepped\",\n",
    "        dataset_id = DATANAME,\n",
    "        selected_fields = selected_fields,\n",
    "        output_types = output_types,\n",
    "        row_restriction = f\"splits='{split}'\",\n",
    "        requested_streams = 3\n",
    "    )\n",
    "    \n",
    "    return training\n",
    "\n",
    "train = bq_reader('TRAIN').parallel_read_rows().prefetch(1).map(transTable).shuffle(args.batch_size*10).batch(args.batch_size)\n",
    "validate = bq_reader('VALIDATE').parallel_read_rows().prefetch(1).map(transTable).batch(args.batch_size)\n",
    "test = bq_reader('TEST').parallel_read_rows().prefetch(1).map(transTable).batch(args.batch_size)\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "# model input definitions\n",
    "feature_columns = {header: tf.feature_column.numeric_column(header) for header in selected_fields if header != args.var_target}\n",
    "feature_layer_inputs = {header: tf.keras.layers.Input(shape = (1,), name = header) for header in selected_fields if header != args.var_target}\n",
    "\n",
    "# feature columns to a Dense Feature Layer\n",
    "feature_layer_outputs = tf.keras.layers.DenseFeatures(feature_columns.values())(feature_layer_inputs)\n",
    "\n",
    "# batch normalization then Dense with softmax activation to nclasses\n",
    "layers = tf.keras.layers.BatchNormalization()(feature_layer_outputs)\n",
    "layers = tf.keras.layers.Dense(nclasses, activation = tf.nn.softmax)(layers)\n",
    "\n",
    "# the model\n",
    "model = tf.keras.Model(\n",
    "    inputs = feature_layer_inputs,\n",
    "    outputs = layers\n",
    ")\n",
    "opt = tf.keras.optimizers.SGD(learning_rate = hparams[HP_LEARNING_RATE], momentum = hparams[HP_MOMENTUM]) #SGD or Adam\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "model.compile(\n",
    "    optimizer = opt,\n",
    "    loss = loss,\n",
    "    metrics = ['accuracy', tf.keras.metrics.AUC(curve='PR')]\n",
    ")\n",
    "\n",
    "# setup tensorboard logs and train\n",
    "log_dir=os.environ['AIP_TENSORBOARD_LOG_DIR']\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir, histogram_freq = 1)\n",
    "hparams_callback = hp.KerasCallback(log_dir + 'train/', hparams)\n",
    "history = model.fit(train, epochs = args.epochs, callbacks = [tensorboard_callback, hparams_callback], validation_data = validate)\n",
    "\n",
    "# output the model save files\n",
    "model.save(os.getenv(\"AIP_MODEL_DIR\"))\n",
    "\n",
    "# report hypertune info back to Vertex AI Training > Hyperparamter Tuning Job\n",
    "hpt = hypertune.HyperTune()\n",
    "hpt.report_hyperparameter_tuning_metric(\n",
    "    hyperparameter_metric_tag = 'loss',\n",
    "    metric_value = history.history['loss'][-1],\n",
    "    global_step = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Custom Container\n",
    "- https://cloud.google.com/vertex-ai/docs/training/create-custom-container\n",
    "- https://cloud.google.com/vertex-ai/docs/training/pre-built-containers\n",
    "- https://cloud.google.com/vertex-ai/docs/general/deep-learning\n",
    "    - https://cloud.google.com/deep-learning-containers/docs/choosing-container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a Base Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcr.io/deeplearning-platform-release/tf-cpu.2-3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_IMAGE # Defined above in Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Dockerfile\n",
    "A basic dockerfile thats take the base image and copies the code in and define an entrypoint - what python script to run first in this case.  Add RUN entries to pip install additional packages.\n",
    "\n",
    "In this case, hyperparameter tuning uses [reports metrics to Vertex AI](https://cloud.google.com/vertex-ai/docs/training/using-hyperparameter-tuning#report-metrics) using the [cloudml-hypertune Python package](https://github.com/GoogleCloudPlatform/cloudml-hypertune) and is missing from the base image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dockerfile = f\"\"\"\n",
    "FROM {BASE_IMAGE}\n",
    "WORKDIR /\n",
    "# Install Additional Packages\n",
    "RUN pip install cloudml-hypertune\n",
    "## Copies the trainer code to the docker image\n",
    "COPY trainer /trainer\n",
    "## Sets up the entry point to invoke the trainer\n",
    "ENTRYPOINT [\"python\", \"-m\", \"trainer.train\"]\n",
    "\"\"\"\n",
    "with open(f'{DIR}/source/Dockerfile', 'w') as f:\n",
    "    f.write(dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Artifact Registry\n",
    "\n",
    "The container will need to be stored in Artifact Registry, Container Registry or Docker Hub in order to be used by Vertex AI Training jobs.  This notebook will setup Artifact registry and push a local (to this notebook) built container to it. \n",
    "\n",
    "https://cloud.google.com/artifact-registry/docs/docker/store-docker-container-images#gcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Enable Artifact Registry API:\n",
    "Check to see if the api is enabled, if not then enable it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifact Registry is Enabled for This Project: ma-mx-presales-lab\n"
     ]
    }
   ],
   "source": [
    "services = !gcloud services list --format=\"json\" --available --filter=name:artifactregistry.googleapis.com\n",
    "services = json.loads(\"\".join(services))\n",
    "\n",
    "if (services[0]['config']['name'] == 'artifactregistry.googleapis.com') & (services[0]['state'] == 'ENABLED'):\n",
    "    print(f\"Artifact Registry is Enabled for This Project: {PROJECT_ID}\")\n",
    "else:\n",
    "    print(f\"Enabeling Artifact Registry for this Project: {PROJECT_ID}\")\n",
    "    !gcloud services enable artifactregistry.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create A Repository\n",
    "Check to see if the registry is already created, if not then create it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is already a repository named ma-mx-presales-lab\n"
     ]
    }
   ],
   "source": [
    "repositories = !gcloud artifacts repositories list --format=\"json\" --filter=REPOSITORY:{PROJECT_ID}\n",
    "repositories = json.loads(\"\".join(repositories[2:]))\n",
    "\n",
    "if len(repositories) > 0:\n",
    "    print(f'There is already a repository named {PROJECT_ID}')\n",
    "else:\n",
    "    print(f'Creating a repository named {PROJECT_ID}')\n",
    "    !gcloud  artifacts repositories create {PROJECT_ID} --repository-format=docker --location={REGION} --description=\"Vertex AI Training Custom Containers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Configure Local Docker to Use GCLOUD CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"us-central1-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build The Custom Container (local to notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-central1-docker.pkg.dev/ma-mx-presales-lab/ma-mx-presales-lab/05i_fraud:latest'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_URI=f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{PROJECT_ID}/{NOTEBOOK}_{DATANAME}:latest\"\n",
    "IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  9.216kB\n",
      "Step 1/5 : FROM gcr.io/deeplearning-platform-release/tf-cpu.2-3\n",
      " ---> 1fdfb6e767fe\n",
      "Step 2/5 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> f8eac7fa0565\n",
      "Step 3/5 : RUN pip install cloudml-hypertune\n",
      " ---> Running in c11608bf3123\n",
      "Collecting cloudml-hypertune\n",
      "  Downloading cloudml-hypertune-0.1.0.dev6.tar.gz (3.2 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: cloudml-hypertune\n",
      "  Building wheel for cloudml-hypertune (setup.py): started\n",
      "  Building wheel for cloudml-hypertune (setup.py): finished with status 'done'\n",
      "  Created wheel for cloudml-hypertune: filename=cloudml_hypertune-0.1.0.dev6-py2.py3-none-any.whl size=3987 sha256=20c6fc29fba89d18c0c09f4d581ab3a8f10768cdd563af1d27a13895ea954d71\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/ff/87/e7bed0c2741fe219b3d6da67c2431d7f7fedb183032e00f81e\n",
      "Successfully built cloudml-hypertune\n",
      "Installing collected packages: cloudml-hypertune\n",
      "Successfully installed cloudml-hypertune-0.1.0.dev6\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container c11608bf3123\n",
      " ---> 174d85334055\n",
      "Step 4/5 : COPY trainer /trainer\n",
      " ---> 41e56714f50f\n",
      "Step 5/5 : ENTRYPOINT [\"python\", \"-m\", \"trainer.train\"]\n",
      " ---> Running in 1468fe9182f6\n",
      "Removing intermediate container 1468fe9182f6\n",
      " ---> bb34e5f04a9d\n",
      "Successfully built bb34e5f04a9d\n",
      "Successfully tagged us-central1-docker.pkg.dev/ma-mx-presales-lab/ma-mx-presales-lab/05i_fraud:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build {DIR}/source/. -t $IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test The Custom Container (local to notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker run {IMAGE_URI} --PROJECT_ID {PROJECT_ID} --DATANAME {DATANAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push The Custom Container To Artifact Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [us-central1-docker.pkg.dev/ma-mx-presales-lab/ma-mx-presales-lab/05i_fraud]\n",
      "\n",
      "\u001b[1B2cd0aff4: Preparing \n",
      "\u001b[1B7b38c047: Preparing \n",
      "\u001b[1Bdf428d24: Preparing \n",
      "\u001b[1B7aa87923: Preparing \n",
      "\u001b[1Baf295f89: Preparing \n",
      "\u001b[1B91940b32: Preparing \n",
      "\u001b[1B95a574c8: Preparing \n",
      "\u001b[1B10151b48: Preparing \n",
      "\u001b[1Bc089358e: Preparing \n",
      "\u001b[1B9b36546a: Preparing \n",
      "\u001b[1B82ce8d0b: Preparing \n",
      "\u001b[1B467ac3a5: Preparing \n",
      "\u001b[1B91c31559: Preparing \n",
      "\u001b[1Bae11254c: Preparing \n",
      "\u001b[1B2bcbe281: Preparing \n",
      "\u001b[1B4c112e39: Preparing \n",
      "\u001b[1B048fd290: Preparing \n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1B7a45d8d8: Preparing \n",
      "\u001b[1B6651fb01: Preparing \n",
      "\u001b[1Bd5cafaa0: Preparing \n",
      "\u001b[22Bcd0aff4: Pushed lready exists 4kB\u001b[21A\u001b[2K\u001b[16A\u001b[2K\u001b[13A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2Klatest: digest: sha256:5f6b848fc51806d765b829d7e991fbcbaa4d7c3741a263e4283551898551e060 size: 4922\n"
     ]
    }
   ],
   "source": [
    "!docker push $IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CMDARGS = [\n",
    "    \"--epochs=\" + str(EPOCHS),\n",
    "    \"--batch_size=\" + str(BATCH_SIZE),\n",
    "    \"--var_target=\" + VAR_TARGET,\n",
    "    \"--var_omit=\" + VAR_OMIT,\n",
    "    \"--project_id=\" + PROJECT_ID,\n",
    "    \"--dataname=\" + DATANAME,\n",
    "    \"--region=\" + REGION,\n",
    "    \"--notebook=\" + NOTEBOOK\n",
    "]\n",
    "\n",
    "MACHINE_SPEC = {\n",
    "    \"machine_type\": TRAIN_COMPUTE,\n",
    "    \"accelerator_count\": 0\n",
    "}\n",
    "\n",
    "WORKER_POOL_SPEC = [\n",
    "    {\n",
    "        \"replica_count\": 1,\n",
    "        \"machine_spec\": MACHINE_SPEC,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": IMAGE_URI,\n",
    "            \"command\": [],\n",
    "            \"args\": CMDARGS\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "customJob = aiplatform.CustomJob(\n",
    "    display_name = f'{NOTEBOOK}_{DATANAME}_{TIMESTAMP}',\n",
    "    worker_pool_specs = WORKER_POOL_SPEC,\n",
    "    base_output_dir = f\"{URI}/{TIMESTAMP}\",\n",
    "    staging_bucket = f\"{URI}/{TIMESTAMP}\",\n",
    "    labels = {'notebook':f'{NOTEBOOK}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Hyperparameter Tuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_SPEC = {\n",
    "    \"loss\": \"minimize\"\n",
    "}\n",
    "\n",
    "PARAMETER_SPEC = {\n",
    "    \"lr\": aiplatform.hyperparameter_tuning.DoubleParameterSpec(min=0.001, max=0.1, scale=\"log\"),\n",
    "    \"m\": aiplatform.hyperparameter_tuning.DoubleParameterSpec(min=1e-7, max=0.9, scale=\"linear\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "htJob = aiplatform.HyperparameterTuningJob(\n",
    "    display_name = f'{NOTEBOOK}_{DATANAME}_{TIMESTAMP}',\n",
    "    custom_job = customJob,\n",
    "    metric_spec = METRIC_SPEC,\n",
    "    parameter_spec = PARAMETER_SPEC,\n",
    "    max_trial_count = 20,\n",
    "    parallel_trial_count = 5,\n",
    "    search_algorithm = None,\n",
    "    labels = {'notebook':f'{NOTEBOOK}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating HyperparameterTuningJob\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob created. Resource name: projects/825075454589/locations/us-central1/hyperparameterTuningJobs/4747405885469360128\n",
      "INFO:google.cloud.aiplatform.jobs:To use this HyperparameterTuningJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:hpt_job = aiplatform.HyperparameterTuningJob.get('projects/825075454589/locations/us-central1/hyperparameterTuningJobs/4747405885469360128')\n",
      "INFO:google.cloud.aiplatform.jobs:View HyperparameterTuningJob:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/4747405885469360128?project=825075454589\n",
      "INFO:google.cloud.aiplatform.jobs:View Tensorboard:\n",
      "https://us-central1.tensorboard.googleusercontent.com/experiment/projects+825075454589+locations+us-central1+tensorboards+6243765894325993472+experiments+4747405885469360128\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/825075454589/locations/us-central1/hyperparameterTuningJobs/4747405885469360128 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/825075454589/locations/us-central1/hyperparameterTuningJobs/4747405885469360128 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/825075454589/locations/us-central1/hyperparameterTuningJobs/4747405885469360128 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/825075454589/locations/us-central1/hyperparameterTuningJobs/4747405885469360128 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/825075454589/locations/us-central1/hyperparameterTuningJobs/4747405885469360128 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/825075454589/locations/us-central1/hyperparameterTuningJobs/4747405885469360128 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/825075454589/locations/us-central1/hyperparameterTuningJobs/4747405885469360128 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/825075454589/locations/us-central1/hyperparameterTuningJobs/4747405885469360128 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/825075454589/locations/us-central1/hyperparameterTuningJobs/4747405885469360128 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/825075454589/locations/us-central1/hyperparameterTuningJobs/4747405885469360128 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/825075454589/locations/us-central1/hyperparameterTuningJobs/4747405885469360128 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/825075454589/locations/us-central1/hyperparameterTuningJobs/4747405885469360128 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/825075454589/locations/us-central1/hyperparameterTuningJobs/4747405885469360128 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/825075454589/locations/us-central1/hyperparameterTuningJobs/4747405885469360128 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/825075454589/locations/us-central1/hyperparameterTuningJobs/4747405885469360128 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/825075454589/locations/us-central1/hyperparameterTuningJobs/4747405885469360128 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob run completed. Resource name: projects/825075454589/locations/us-central1/hyperparameterTuningJobs/4747405885469360128\n"
     ]
    }
   ],
   "source": [
    "htJob.run(\n",
    "    service_account = SERVICE_ACCOUNT,\n",
    "    tensorboard = tb.resource_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.004580758512020111,\n",
       " 0.004569855984300375,\n",
       " 0.0036965347826480865,\n",
       " 0.0035011235158890486,\n",
       " 0.005478507373481989,\n",
       " 0.004580274224281311,\n",
       " 0.0033361068926751614,\n",
       " 0.0038007372058928013,\n",
       " 0.003558974713087082,\n",
       " 0.0035873777233064175,\n",
       " 0.0037931501865386963,\n",
       " 0.0035744199994951487,\n",
       " 0.003583424026146531,\n",
       " 0.0033743027597665787,\n",
       " 0.003488971386104822,\n",
       " 0.0035540463868528605,\n",
       " 0.003455731552094221,\n",
       " 0.0035074602346867323,\n",
       " 0.0034617020282894373,\n",
       " 0.0034086769446730614]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if trial.state.name == 'SUCCEEDED'\n",
    "losses = [trial.final_measurement.metrics[0].value if trial.state.name == 'SUCCEEDED' else 1 for trial in htJob.trials]\n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id: \"7\"\n",
       "state: SUCCEEDED\n",
       "parameters {\n",
       "  parameter_id: \"lr\"\n",
       "  value {\n",
       "    number_value: 0.1\n",
       "  }\n",
       "}\n",
       "parameters {\n",
       "  parameter_id: \"m\"\n",
       "  value {\n",
       "    number_value: 0.5374021865996481\n",
       "  }\n",
       "}\n",
       "final_measurement {\n",
       "  step_count: 1\n",
       "  metrics {\n",
       "    metric_id: \"loss\"\n",
       "    value: 0.0033361068926751614\n",
       "  }\n",
       "}\n",
       "start_time {\n",
       "  seconds: 1649211852\n",
       "  nanos: 315811020\n",
       "}\n",
       "end_time {\n",
       "  seconds: 1649212464\n",
       "}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = htJob.trials[losses.index(min(losses))]\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir $DIR/all_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/1/logs/train/events.out.tfevents.1649211294.51b6e0148ebc.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/1/logs/train/events.out.tfevents.1649211294.51b6e0148ebc.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/1/logs/train/events.out.tfevents.1649211298.51b6e0148ebc.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/1/logs/train/plugins/profile/2022_04_06_02_14_57/51b6e0148ebc.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/1/logs/train/plugins/profile/2022_04_06_02_14_57/51b6e0148ebc.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/1/logs/train/plugins/profile/2022_04_06_02_14_57/51b6e0148ebc.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/1/logs/train/plugins/profile/2022_04_06_02_14_57/51b6e0148ebc.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/1/logs/train/plugins/profile/2022_04_06_02_14_57/51b6e0148ebc.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/1/logs/train/plugins/profile/2022_04_06_02_14_57/51b6e0148ebc.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/1/logs/train/plugins/profile/2022_04_06_02_14_57/51b6e0148ebc.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/1/logs/validation/events.out.tfevents.1649211328.51b6e0148ebc.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/1/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/1/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/1/model/variables/variables.index...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/10/logs/train/events.out.tfevents.1649212146.34468feedd00.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/10/logs/train/events.out.tfevents.1649212147.34468feedd00.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/10/logs/train/events.out.tfevents.1649212150.34468feedd00.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/10/logs/train/plugins/profile/2022_04_06_02_29_09/34468feedd00.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/10/logs/train/plugins/profile/2022_04_06_02_29_09/34468feedd00.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/10/logs/train/plugins/profile/2022_04_06_02_29_09/34468feedd00.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/10/logs/train/plugins/profile/2022_04_06_02_29_09/34468feedd00.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/10/logs/train/plugins/profile/2022_04_06_02_29_09/34468feedd00.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/10/logs/train/plugins/profile/2022_04_06_02_29_09/34468feedd00.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/10/logs/train/plugins/profile/2022_04_06_02_29_09/34468feedd00.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/10/logs/validation/events.out.tfevents.1649212178.34468feedd00.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/10/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/10/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/10/model/variables/variables.index...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/11/logs/train/events.out.tfevents.1649212731.db81245a8c97.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/11/logs/train/events.out.tfevents.1649212731.db81245a8c97.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/11/logs/train/events.out.tfevents.1649212735.db81245a8c97.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/11/logs/train/plugins/profile/2022_04_06_02_38_54/db81245a8c97.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/11/logs/train/plugins/profile/2022_04_06_02_38_54/db81245a8c97.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/11/logs/train/plugins/profile/2022_04_06_02_38_54/db81245a8c97.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/11/logs/train/plugins/profile/2022_04_06_02_38_54/db81245a8c97.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/11/logs/train/plugins/profile/2022_04_06_02_38_54/db81245a8c97.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/11/logs/train/plugins/profile/2022_04_06_02_38_54/db81245a8c97.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/11/logs/train/plugins/profile/2022_04_06_02_38_54/db81245a8c97.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/11/logs/validation/events.out.tfevents.1649212769.db81245a8c97.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/11/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/11/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/11/model/variables/variables.index...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/12/logs/train/events.out.tfevents.1649212850.f75dbfd6fb01.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/12/logs/train/events.out.tfevents.1649212850.f75dbfd6fb01.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/12/logs/train/events.out.tfevents.1649212854.f75dbfd6fb01.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/12/logs/train/plugins/profile/2022_04_06_02_40_53/f75dbfd6fb01.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/12/logs/train/plugins/profile/2022_04_06_02_40_53/f75dbfd6fb01.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/12/logs/train/plugins/profile/2022_04_06_02_40_53/f75dbfd6fb01.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/12/logs/train/plugins/profile/2022_04_06_02_40_53/f75dbfd6fb01.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/12/logs/train/plugins/profile/2022_04_06_02_40_53/f75dbfd6fb01.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/12/logs/train/plugins/profile/2022_04_06_02_40_53/f75dbfd6fb01.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/12/logs/train/plugins/profile/2022_04_06_02_40_53/f75dbfd6fb01.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/12/logs/validation/events.out.tfevents.1649212901.f75dbfd6fb01.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/12/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/12/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/12/model/variables/variables.index...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/13/logs/train/events.out.tfevents.1649212882.cc519af94fdb.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/13/logs/train/events.out.tfevents.1649212882.cc519af94fdb.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/13/logs/train/events.out.tfevents.1649212886.cc519af94fdb.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/13/logs/train/plugins/profile/2022_04_06_02_41_25/cc519af94fdb.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/13/logs/train/plugins/profile/2022_04_06_02_41_25/cc519af94fdb.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/13/logs/train/plugins/profile/2022_04_06_02_41_25/cc519af94fdb.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/13/logs/train/plugins/profile/2022_04_06_02_41_25/cc519af94fdb.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/13/logs/train/plugins/profile/2022_04_06_02_41_25/cc519af94fdb.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/13/logs/train/plugins/profile/2022_04_06_02_41_25/cc519af94fdb.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/13/logs/train/plugins/profile/2022_04_06_02_41_25/cc519af94fdb.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/13/logs/validation/events.out.tfevents.1649212917.cc519af94fdb.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/13/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/13/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/13/model/variables/variables.index...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/14/logs/train/events.out.tfevents.1649212886.7513eb207a4b.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/14/logs/train/events.out.tfevents.1649212886.7513eb207a4b.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/14/logs/train/events.out.tfevents.1649212890.7513eb207a4b.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/14/logs/train/plugins/profile/2022_04_06_02_41_29/7513eb207a4b.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/14/logs/train/plugins/profile/2022_04_06_02_41_29/7513eb207a4b.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/14/logs/train/plugins/profile/2022_04_06_02_41_29/7513eb207a4b.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/14/logs/train/plugins/profile/2022_04_06_02_41_29/7513eb207a4b.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/14/logs/train/plugins/profile/2022_04_06_02_41_29/7513eb207a4b.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/14/logs/train/plugins/profile/2022_04_06_02_41_29/7513eb207a4b.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/14/logs/train/plugins/profile/2022_04_06_02_41_29/7513eb207a4b.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/14/logs/validation/events.out.tfevents.1649212923.7513eb207a4b.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/14/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/14/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/14/model/variables/variables.index...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/15/logs/train/events.out.tfevents.1649212881.edc517d16128.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/15/logs/train/events.out.tfevents.1649212881.edc517d16128.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/15/logs/train/events.out.tfevents.1649212885.edc517d16128.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/15/logs/train/plugins/profile/2022_04_06_02_41_24/edc517d16128.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/15/logs/train/plugins/profile/2022_04_06_02_41_24/edc517d16128.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/15/logs/train/plugins/profile/2022_04_06_02_41_24/edc517d16128.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/15/logs/train/plugins/profile/2022_04_06_02_41_24/edc517d16128.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/15/logs/train/plugins/profile/2022_04_06_02_41_24/edc517d16128.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/15/logs/train/plugins/profile/2022_04_06_02_41_24/edc517d16128.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/15/logs/train/plugins/profile/2022_04_06_02_41_24/edc517d16128.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/15/logs/validation/events.out.tfevents.1649212914.edc517d16128.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/15/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/15/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/15/model/variables/variables.index...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/16/logs/train/events.out.tfevents.1649213585.09bba12f603a.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/16/logs/train/events.out.tfevents.1649213585.09bba12f603a.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/16/logs/train/events.out.tfevents.1649213589.09bba12f603a.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/16/logs/train/plugins/profile/2022_04_06_02_53_09/09bba12f603a.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/16/logs/train/plugins/profile/2022_04_06_02_53_09/09bba12f603a.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/16/logs/train/plugins/profile/2022_04_06_02_53_09/09bba12f603a.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/16/logs/train/plugins/profile/2022_04_06_02_53_09/09bba12f603a.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/16/logs/train/plugins/profile/2022_04_06_02_53_09/09bba12f603a.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/16/logs/train/plugins/profile/2022_04_06_02_53_09/09bba12f603a.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/16/logs/train/plugins/profile/2022_04_06_02_53_09/09bba12f603a.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/16/logs/validation/events.out.tfevents.1649213622.09bba12f603a.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/16/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/16/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/16/model/variables/variables.index...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/17/logs/train/events.out.tfevents.1649213585.c623fdf41bf9.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/17/logs/train/events.out.tfevents.1649213586.c623fdf41bf9.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/17/logs/train/events.out.tfevents.1649213589.c623fdf41bf9.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/17/logs/train/plugins/profile/2022_04_06_02_53_09/c623fdf41bf9.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/17/logs/train/plugins/profile/2022_04_06_02_53_09/c623fdf41bf9.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/17/logs/train/plugins/profile/2022_04_06_02_53_09/c623fdf41bf9.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/17/logs/train/plugins/profile/2022_04_06_02_53_09/c623fdf41bf9.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/17/logs/train/plugins/profile/2022_04_06_02_53_09/c623fdf41bf9.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/17/logs/train/plugins/profile/2022_04_06_02_53_09/c623fdf41bf9.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/17/logs/train/plugins/profile/2022_04_06_02_53_09/c623fdf41bf9.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/17/logs/validation/events.out.tfevents.1649213622.c623fdf41bf9.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/17/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/17/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/17/model/variables/variables.index...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/18/logs/train/events.out.tfevents.1649213614.e94e1046b303.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/18/logs/train/events.out.tfevents.1649213614.e94e1046b303.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/18/logs/train/events.out.tfevents.1649213619.e94e1046b303.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/18/logs/train/plugins/profile/2022_04_06_02_53_38/e94e1046b303.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/18/logs/train/plugins/profile/2022_04_06_02_53_38/e94e1046b303.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/18/logs/train/plugins/profile/2022_04_06_02_53_38/e94e1046b303.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/18/logs/train/plugins/profile/2022_04_06_02_53_38/e94e1046b303.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/18/logs/train/plugins/profile/2022_04_06_02_53_38/e94e1046b303.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/18/logs/train/plugins/profile/2022_04_06_02_53_38/e94e1046b303.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/18/logs/train/plugins/profile/2022_04_06_02_53_38/e94e1046b303.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/18/logs/validation/events.out.tfevents.1649213648.e94e1046b303.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/18/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/18/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/18/model/variables/variables.index...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/19/logs/train/events.out.tfevents.1649213651.9cf94b210f0a.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/19/logs/train/events.out.tfevents.1649213651.9cf94b210f0a.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/19/logs/train/events.out.tfevents.1649213654.9cf94b210f0a.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/19/logs/train/plugins/profile/2022_04_06_02_54_13/9cf94b210f0a.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/19/logs/train/plugins/profile/2022_04_06_02_54_13/9cf94b210f0a.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/19/logs/train/plugins/profile/2022_04_06_02_54_13/9cf94b210f0a.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/19/logs/train/plugins/profile/2022_04_06_02_54_13/9cf94b210f0a.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/19/logs/train/plugins/profile/2022_04_06_02_54_13/9cf94b210f0a.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/19/logs/train/plugins/profile/2022_04_06_02_54_13/9cf94b210f0a.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/19/logs/train/plugins/profile/2022_04_06_02_54_13/9cf94b210f0a.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/19/logs/validation/events.out.tfevents.1649213685.9cf94b210f0a.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/19/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/19/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/19/model/variables/variables.index...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/2/logs/train/events.out.tfevents.1649211308.1feee26d0707.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/2/logs/train/events.out.tfevents.1649211309.1feee26d0707.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/2/logs/train/events.out.tfevents.1649211313.1feee26d0707.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/2/logs/train/plugins/profile/2022_04_06_02_15_12/1feee26d0707.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/2/logs/train/plugins/profile/2022_04_06_02_15_12/1feee26d0707.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/2/logs/train/plugins/profile/2022_04_06_02_15_12/1feee26d0707.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/2/logs/train/plugins/profile/2022_04_06_02_15_12/1feee26d0707.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/2/logs/train/plugins/profile/2022_04_06_02_15_12/1feee26d0707.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/2/logs/train/plugins/profile/2022_04_06_02_15_12/1feee26d0707.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/2/logs/train/plugins/profile/2022_04_06_02_15_12/1feee26d0707.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/2/logs/validation/events.out.tfevents.1649211352.1feee26d0707.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/2/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/2/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/2/model/variables/variables.index...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/20/logs/train/events.out.tfevents.1649213686.df5d5bcdce3a.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/20/logs/train/events.out.tfevents.1649213686.df5d5bcdce3a.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/20/logs/train/events.out.tfevents.1649213690.df5d5bcdce3a.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/20/logs/train/plugins/profile/2022_04_06_02_54_49/df5d5bcdce3a.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/20/logs/train/plugins/profile/2022_04_06_02_54_49/df5d5bcdce3a.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/20/logs/train/plugins/profile/2022_04_06_02_54_49/df5d5bcdce3a.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/20/logs/train/plugins/profile/2022_04_06_02_54_49/df5d5bcdce3a.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/20/logs/train/plugins/profile/2022_04_06_02_54_49/df5d5bcdce3a.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/20/logs/train/plugins/profile/2022_04_06_02_54_49/df5d5bcdce3a.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/20/logs/train/plugins/profile/2022_04_06_02_54_49/df5d5bcdce3a.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/20/logs/validation/events.out.tfevents.1649213735.df5d5bcdce3a.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/20/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/20/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/20/model/variables/variables.index...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/3/logs/train/events.out.tfevents.1649211293.46ef0e0d7173.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/3/logs/train/events.out.tfevents.1649211294.46ef0e0d7173.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/3/logs/train/events.out.tfevents.1649211297.46ef0e0d7173.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/3/logs/train/plugins/profile/2022_04_06_02_14_56/46ef0e0d7173.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/3/logs/train/plugins/profile/2022_04_06_02_14_56/46ef0e0d7173.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/3/logs/train/plugins/profile/2022_04_06_02_14_56/46ef0e0d7173.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/3/logs/train/plugins/profile/2022_04_06_02_14_56/46ef0e0d7173.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/3/logs/train/plugins/profile/2022_04_06_02_14_56/46ef0e0d7173.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/3/logs/train/plugins/profile/2022_04_06_02_14_56/46ef0e0d7173.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/3/logs/train/plugins/profile/2022_04_06_02_14_56/46ef0e0d7173.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/3/logs/validation/events.out.tfevents.1649211330.46ef0e0d7173.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/3/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/3/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/3/model/variables/variables.index...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/4/logs/train/events.out.tfevents.1649211291.1e3e750d5859.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/4/logs/train/events.out.tfevents.1649211291.1e3e750d5859.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/4/logs/train/events.out.tfevents.1649211295.1e3e750d5859.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/4/logs/train/plugins/profile/2022_04_06_02_14_54/1e3e750d5859.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/4/logs/train/plugins/profile/2022_04_06_02_14_54/1e3e750d5859.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/4/logs/train/plugins/profile/2022_04_06_02_14_54/1e3e750d5859.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/4/logs/train/plugins/profile/2022_04_06_02_14_54/1e3e750d5859.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/4/logs/train/plugins/profile/2022_04_06_02_14_54/1e3e750d5859.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/4/logs/train/plugins/profile/2022_04_06_02_14_54/1e3e750d5859.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/4/logs/train/plugins/profile/2022_04_06_02_14_54/1e3e750d5859.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/4/logs/validation/events.out.tfevents.1649211326.1e3e750d5859.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/4/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/4/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/4/model/variables/variables.index...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/5/logs/train/events.out.tfevents.1649211290.97b06003ef39.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/5/logs/train/events.out.tfevents.1649211291.97b06003ef39.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/5/logs/train/events.out.tfevents.1649211294.97b06003ef39.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/5/logs/train/plugins/profile/2022_04_06_02_14_53/97b06003ef39.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/5/logs/train/plugins/profile/2022_04_06_02_14_53/97b06003ef39.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/5/logs/train/plugins/profile/2022_04_06_02_14_53/97b06003ef39.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/5/logs/train/plugins/profile/2022_04_06_02_14_53/97b06003ef39.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/5/logs/train/plugins/profile/2022_04_06_02_14_53/97b06003ef39.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/5/logs/train/plugins/profile/2022_04_06_02_14_53/97b06003ef39.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/5/logs/train/plugins/profile/2022_04_06_02_14_53/97b06003ef39.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/5/logs/validation/events.out.tfevents.1649211326.97b06003ef39.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/5/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/5/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/5/model/variables/variables.index...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/6/logs/train/events.out.tfevents.1649212004.8dff0fb7b777.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/6/logs/train/events.out.tfevents.1649212004.8dff0fb7b777.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/6/logs/train/events.out.tfevents.1649212008.8dff0fb7b777.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/6/logs/train/plugins/profile/2022_04_06_02_26_47/8dff0fb7b777.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/6/logs/train/plugins/profile/2022_04_06_02_26_47/8dff0fb7b777.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/6/logs/train/plugins/profile/2022_04_06_02_26_47/8dff0fb7b777.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/6/logs/train/plugins/profile/2022_04_06_02_26_47/8dff0fb7b777.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/6/logs/train/plugins/profile/2022_04_06_02_26_47/8dff0fb7b777.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/6/logs/train/plugins/profile/2022_04_06_02_26_47/8dff0fb7b777.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/6/logs/train/plugins/profile/2022_04_06_02_26_47/8dff0fb7b777.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/6/logs/validation/events.out.tfevents.1649212034.8dff0fb7b777.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/6/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/6/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/6/model/variables/variables.index...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/7/logs/train/events.out.tfevents.1649212012.c1899fd93e5f.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/7/logs/train/events.out.tfevents.1649212012.c1899fd93e5f.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/7/logs/train/events.out.tfevents.1649212017.c1899fd93e5f.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/7/logs/train/plugins/profile/2022_04_06_02_26_56/c1899fd93e5f.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/7/logs/train/plugins/profile/2022_04_06_02_26_56/c1899fd93e5f.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/7/logs/train/plugins/profile/2022_04_06_02_26_56/c1899fd93e5f.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/7/logs/train/plugins/profile/2022_04_06_02_26_56/c1899fd93e5f.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/7/logs/train/plugins/profile/2022_04_06_02_26_56/c1899fd93e5f.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/7/logs/train/plugins/profile/2022_04_06_02_26_56/c1899fd93e5f.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/7/logs/train/plugins/profile/2022_04_06_02_26_56/c1899fd93e5f.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/7/logs/validation/events.out.tfevents.1649212053.c1899fd93e5f.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/7/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/7/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/7/model/variables/variables.index...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/8/logs/train/events.out.tfevents.1649212032.9d763cfe6a5e.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/8/logs/train/events.out.tfevents.1649212032.9d763cfe6a5e.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/8/logs/train/events.out.tfevents.1649212037.9d763cfe6a5e.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/8/logs/train/plugins/profile/2022_04_06_02_27_16/9d763cfe6a5e.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/8/logs/train/plugins/profile/2022_04_06_02_27_16/9d763cfe6a5e.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/8/logs/train/plugins/profile/2022_04_06_02_27_16/9d763cfe6a5e.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/8/logs/train/plugins/profile/2022_04_06_02_27_16/9d763cfe6a5e.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/8/logs/train/plugins/profile/2022_04_06_02_27_16/9d763cfe6a5e.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/8/logs/train/plugins/profile/2022_04_06_02_27_16/9d763cfe6a5e.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/8/logs/train/plugins/profile/2022_04_06_02_27_16/9d763cfe6a5e.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/8/logs/validation/events.out.tfevents.1649212076.9d763cfe6a5e.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/8/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/8/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/8/model/variables/variables.index...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/9/logs/train/events.out.tfevents.1649212109.a80856cb1689.1.723.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/9/logs/train/events.out.tfevents.1649212109.a80856cb1689.1.739.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/9/logs/train/events.out.tfevents.1649212113.a80856cb1689.profile-empty...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/9/logs/train/plugins/profile/2022_04_06_02_28_32/a80856cb1689.input_pipeline.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/9/logs/train/plugins/profile/2022_04_06_02_28_32/a80856cb1689.kernel_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/9/logs/train/plugins/profile/2022_04_06_02_28_32/a80856cb1689.memory_profile.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/9/logs/train/plugins/profile/2022_04_06_02_28_32/a80856cb1689.overview_page.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/9/logs/train/plugins/profile/2022_04_06_02_28_32/a80856cb1689.tensorflow_stats.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/9/logs/train/plugins/profile/2022_04_06_02_28_32/a80856cb1689.trace.json.gz...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/9/logs/train/plugins/profile/2022_04_06_02_28_32/a80856cb1689.xplane.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/9/logs/validation/events.out.tfevents.1649212144.a80856cb1689.1.9240.v2...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/9/model/saved_model.pb...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/9/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/9/model/variables/variables.index...\n",
      "\\ [280 files][ 15.2 MiB/ 15.2 MiB]  765.7 KiB/s                                 \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "\n",
      "Operation completed over 280 objects/15.2 MiB.                                   \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r gs://vertex-ai-mlops-bucket/fraud/models/05i/20220406020648/* $DIR/all_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e779c9436ad74912\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e779c9436ad74912\");\n",
       "          const url = new URL(\"/proxy/6008/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir $DIR/all_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-06 03:09:19.271814: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-04-06 03:09:19.271870: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-06 03:09:19.271895: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tensorflow-2-7-20220125-120050): /proc/driver/nvidia/version does not exist\n",
      "\n",
      "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/XSMdMKilTZCahz52xdRF9g/\n",
      "\n",
      "\u001b[1m[2022-04-06T03:09:19]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2022-04-06T03:09:40]\u001b[0m Total uploaded: 1200 scalars, 1240 tensors (494.0 kB), 20 binary objects (927.3 kB)\n",
      "\u001b[1m[2022-04-06T03:09:40]\u001b[0m Done scanning logdir.\n",
      "\n",
      "\n",
      "Done. View your TensorBoard at https://tensorboard.dev/experiment/XSMdMKilTZCahz52xdRF9g/\n"
     ]
    }
   ],
   "source": [
    "!tensorboard dev upload --logdir $DIR/all_logs \\\n",
    "  --name \"Vertex hyperparameter tunning with custom container\" \\\n",
    "  --description \"Training results from Notebook 05i: hyperparameter tunning\" \\\n",
    "  --one_shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Model\n",
      "INFO:google.cloud.aiplatform.models:Create Model backing LRO: projects/715288179162/locations/us-central1/models/8122263918195245056/operations/6548951358253301760\n",
      "INFO:google.cloud.aiplatform.models:Model created. Resource name: projects/715288179162/locations/us-central1/models/8122263918195245056\n",
      "INFO:google.cloud.aiplatform.models:To use this Model in another session:\n",
      "INFO:google.cloud.aiplatform.models:model = aiplatform.Model('projects/715288179162/locations/us-central1/models/8122263918195245056')\n"
     ]
    }
   ],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name = f'{NOTEBOOK}_{DATANAME}_{TIMESTAMP}',\n",
    "    serving_container_image_uri = DEPLOY_IMAGE,\n",
    "    artifact_uri = f\"{URI}/{TIMESTAMP}/{best.id}/model\",\n",
    "    labels = {'notebook':f'{NOTEBOOK}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05i_fraud_20220313140425'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create An Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Endpoint\n",
      "INFO:google.cloud.aiplatform.models:Create Endpoint backing LRO: projects/715288179162/locations/us-central1/endpoints/2951168373787983872/operations/6166145389926809600\n",
      "INFO:google.cloud.aiplatform.models:Endpoint created. Resource name: projects/715288179162/locations/us-central1/endpoints/2951168373787983872\n",
      "INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n",
      "INFO:google.cloud.aiplatform.models:endpoint = aiplatform.Endpoint('projects/715288179162/locations/us-central1/endpoints/2951168373787983872')\n"
     ]
    }
   ],
   "source": [
    "endpoint = aiplatform.Endpoint.create(\n",
    "    display_name = f'{NOTEBOOK}_{DATANAME}_{TIMESTAMP}',\n",
    "    labels = {'notebook':f'{NOTEBOOK}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05i_fraud_20220313140425'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Model To Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Deploying Model projects/715288179162/locations/us-central1/models/8122263918195245056 to Endpoint : projects/715288179162/locations/us-central1/endpoints/2951168373787983872\n",
      "INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/715288179162/locations/us-central1/endpoints/2951168373787983872/operations/3860302380713115648\n",
      "INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/715288179162/locations/us-central1/endpoints/2951168373787983872\n"
     ]
    }
   ],
   "source": [
    "endpoint.deploy(\n",
    "    model = model,\n",
    "    deployed_model_display_name = f'{NOTEBOOK}_{DATANAME}_{TIMESTAMP}',\n",
    "    traffic_percentage = 100,\n",
    "    machine_type = DEPLOY_COMPUTE,\n",
    "    min_replica_count = 1,\n",
    "    max_replica_count = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare a record for prediction: instance and parameters lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bigquery.query(query = f\"SELECT * FROM {DATANAME}.{DATANAME}_prepped WHERE splits='TEST' LIMIT 10\").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7148</td>\n",
       "      <td>1.156386</td>\n",
       "      <td>0.193513</td>\n",
       "      <td>0.242220</td>\n",
       "      <td>0.660729</td>\n",
       "      <td>0.236144</td>\n",
       "      <td>0.311471</td>\n",
       "      <td>-0.088420</td>\n",
       "      <td>0.057844</td>\n",
       "      <td>1.123405</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051662</td>\n",
       "      <td>-0.262183</td>\n",
       "      <td>0.477870</td>\n",
       "      <td>0.556403</td>\n",
       "      <td>-0.046953</td>\n",
       "      <td>-0.021878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0eddc3ef-a61b-4fba-a3ab-0ed9a726dcf0</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76311</td>\n",
       "      <td>-0.186529</td>\n",
       "      <td>0.545755</td>\n",
       "      <td>2.432618</td>\n",
       "      <td>3.266129</td>\n",
       "      <td>-0.784549</td>\n",
       "      <td>3.167033</td>\n",
       "      <td>-2.460489</td>\n",
       "      <td>-1.830983</td>\n",
       "      <td>0.389492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400380</td>\n",
       "      <td>-1.265280</td>\n",
       "      <td>1.231000</td>\n",
       "      <td>0.749402</td>\n",
       "      <td>0.147862</td>\n",
       "      <td>0.187856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>b1111e03-a559-4eb4-ab32-e3aea0072ef7</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>125139</td>\n",
       "      <td>1.879049</td>\n",
       "      <td>0.212473</td>\n",
       "      <td>-0.085529</td>\n",
       "      <td>3.554091</td>\n",
       "      <td>0.205505</td>\n",
       "      <td>1.188395</td>\n",
       "      <td>-0.672662</td>\n",
       "      <td>0.375249</td>\n",
       "      <td>-0.494351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131433</td>\n",
       "      <td>0.256023</td>\n",
       "      <td>-0.135450</td>\n",
       "      <td>0.048878</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>-0.042219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0a0f4b69-01ee-436e-ae52-02237cd6433e</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51632</td>\n",
       "      <td>1.264050</td>\n",
       "      <td>0.182193</td>\n",
       "      <td>0.020910</td>\n",
       "      <td>0.478060</td>\n",
       "      <td>-0.037823</td>\n",
       "      <td>-0.490973</td>\n",
       "      <td>0.166690</td>\n",
       "      <td>-0.130607</td>\n",
       "      <td>-0.157200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167644</td>\n",
       "      <td>0.075563</td>\n",
       "      <td>0.698539</td>\n",
       "      <td>0.556361</td>\n",
       "      <td>-0.052595</td>\n",
       "      <td>-0.011799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>ed678d6e-8dea-4d45-92b7-74e7eba22402</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0    7148  1.156386  0.193513  0.242220  0.660729  0.236144  0.311471   \n",
       "1   76311 -0.186529  0.545755  2.432618  3.266129 -0.784549  3.167033   \n",
       "2  125139  1.879049  0.212473 -0.085529  3.554091  0.205505  1.188395   \n",
       "3   51632  1.264050  0.182193  0.020910  0.478060 -0.037823 -0.490973   \n",
       "\n",
       "         V7        V8        V9  ...       V23       V24       V25       V26  \\\n",
       "0 -0.088420  0.057844  1.123405  ... -0.051662 -0.262183  0.477870  0.556403   \n",
       "1 -2.460489 -1.830983  0.389492  ... -0.400380 -1.265280  1.231000  0.749402   \n",
       "2 -0.672662  0.375249 -0.494351  ...  0.131433  0.256023 -0.135450  0.048878   \n",
       "3  0.166690 -0.130607 -0.157200  ... -0.167644  0.075563  0.698539  0.556361   \n",
       "\n",
       "        V27       V28  Amount  Class                        transaction_id  \\\n",
       "0 -0.046953 -0.021878     0.0      0  0eddc3ef-a61b-4fba-a3ab-0ed9a726dcf0   \n",
       "1  0.147862  0.187856     0.0      0  b1111e03-a559-4eb4-ab32-e3aea0072ef7   \n",
       "2  0.003082 -0.042219     0.0      0  0a0f4b69-01ee-436e-ae52-02237cd6433e   \n",
       "3 -0.052595 -0.011799     0.0      0  ed678d6e-8dea-4d45-92b7-74e7eba22402   \n",
       "\n",
       "   splits  \n",
       "0    TEST  \n",
       "1    TEST  \n",
       "2    TEST  \n",
       "3    TEST  \n",
       "\n",
       "[4 rows x 33 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "newob = pred[pred.columns[~pred.columns.isin(VAR_OMIT.split()+[VAR_TARGET, 'splits'])]].to_dict(orient='records')[0]\n",
    "#newob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [json_format.ParseDict(newob, Value())]\n",
    "parameters = json_format.ParseDict({}, Value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Predictions: Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[[0.999886394, 0.000113604474]], deployed_model_id='5686172761555206144', explanations=None)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = endpoint.predict(instances=instances, parameters=parameters)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.999886394, 0.000113604474]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction.predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Predictions: REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DIR}/request.json','w') as file:\n",
    "    file.write(json.dumps({\"instances\": [newob]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predictions\": [\n",
      "    [\n",
      "      0.999886394,\n",
      "      0.000113604474\n",
      "    ]\n",
      "  ],\n",
      "  \"deployedModelId\": \"5686172761555206144\",\n",
      "  \"model\": \"projects/715288179162/locations/us-central1/models/8122263918195245056\",\n",
      "  \"modelDisplayName\": \"05i_fraud_20220313140425\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST \\\n",
    "-H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
    "-H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "-d @{DIR}/request.json \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Predictions: gcloud (CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n",
      "[[0.999886394, 0.000113604474]]\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta ai endpoints predict {endpoint.name.rsplit('/',1)[-1]} --region={REGION} --json-request={DIR}/request.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "see notebook \"99 - Cleanup\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
